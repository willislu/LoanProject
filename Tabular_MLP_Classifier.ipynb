{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5742ffe2",
   "metadata": {},
   "source": [
    "\n",
    "# PyTorch Tabular Binary Classifier (MLP) — Loan Default (`bad_flag`)\n",
    "\n",
    "This notebook trains a **Multi-Layer Perceptron (MLP)** on your tabular dataset to predict `bad_flag` (binary target).\n",
    "\n",
    "> **Data assumption:** Rows with `bad_flag` = NaN are treated as **test** rows for inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14240ee4",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Requirements\n",
    "Run this once to install dependencies (if needed):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c663dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running locally and you need packages, uncomment:\n",
    "#!pip install torch scikit-learn pandas joblib openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8a978",
   "metadata": {},
   "source": [
    "## 1) Imports & Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38687697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os, json, random, math\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5815e4",
   "metadata": {},
   "source": [
    "## 2) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "215ff338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291962, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>desc</th>\n",
       "      <th>...</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>application_approved_flag</th>\n",
       "      <th>internal_score</th>\n",
       "      <th>bad_flag</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>desc_length</th>\n",
       "      <th>has_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10000001</td>\n",
       "      <td>11983056</td>\n",
       "      <td>7550</td>\n",
       "      <td>36</td>\n",
       "      <td>16.24</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3828.953801</td>\n",
       "      <td>5759.0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10000002</td>\n",
       "      <td>12002921</td>\n",
       "      <td>27050</td>\n",
       "      <td>36</td>\n",
       "      <td>10.99</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>OWN</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Borrower added on 12/31/13 &gt; Combining high ...</td>\n",
       "      <td>...</td>\n",
       "      <td>35700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34359.940730</td>\n",
       "      <td>114834.0</td>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10000003</td>\n",
       "      <td>11983096</td>\n",
       "      <td>12000</td>\n",
       "      <td>36</td>\n",
       "      <td>10.99</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>Borrower added on 12/31/13 &gt; I would like to...</td>\n",
       "      <td>...</td>\n",
       "      <td>18100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16416.617760</td>\n",
       "      <td>7137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10000004</td>\n",
       "      <td>12003142</td>\n",
       "      <td>28000</td>\n",
       "      <td>36</td>\n",
       "      <td>7.62</td>\n",
       "      <td>5 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>42200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38014.149760</td>\n",
       "      <td>799592.0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10000005</td>\n",
       "      <td>11993233</td>\n",
       "      <td>12000</td>\n",
       "      <td>36</td>\n",
       "      <td>13.53</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6471.462236</td>\n",
       "      <td>13605.0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        id  member_id  loan_amnt  term  int_rate emp_length  \\\n",
       "0           0  10000001   11983056       7550    36     16.24    3 years   \n",
       "1           1  10000002   12002921      27050    36     10.99  10+ years   \n",
       "2           2  10000003   11983096      12000    36     10.99    4 years   \n",
       "3           3  10000004   12003142      28000    36      7.62    5 years   \n",
       "4           4  10000005   11993233      12000    36     13.53  10+ years   \n",
       "\n",
       "  home_ownership  annual_inc  \\\n",
       "0           RENT     28000.0   \n",
       "1            OWN     55000.0   \n",
       "2           RENT     60000.0   \n",
       "3       MORTGAGE    325000.0   \n",
       "4           RENT     40000.0   \n",
       "\n",
       "                                                desc  ... total_bc_limit  \\\n",
       "0                                                NaN  ...         4000.0   \n",
       "1    Borrower added on 12/31/13 > Combining high ...  ...        35700.0   \n",
       "2    Borrower added on 12/31/13 > I would like to...  ...        18100.0   \n",
       "3                                                NaN  ...        42200.0   \n",
       "4                                                NaN  ...         7000.0   \n",
       "\n",
       "   mths_since_last_major_derog  tot_hi_cred_lim  tot_cur_bal  \\\n",
       "0                          NaN      3828.953801       5759.0   \n",
       "1                          NaN     34359.940730     114834.0   \n",
       "2                          NaN     16416.617760       7137.0   \n",
       "3                          NaN     38014.149760     799592.0   \n",
       "4                         53.0      6471.462236      13605.0   \n",
       "\n",
       "   application_approved_flag  internal_score  bad_flag  emp_length_num  \\\n",
       "0                          1              99       0.0             3.0   \n",
       "1                          1             353       0.0            10.0   \n",
       "2                          1             157       0.0             4.0   \n",
       "3                          1             365       0.0             5.0   \n",
       "4                          1             157       0.0            10.0   \n",
       "\n",
       "   desc_length  has_desc  \n",
       "0            0         0  \n",
       "1           95         1  \n",
       "2          176         1  \n",
       "3            0         0  \n",
       "4            0         0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Update the path if needed\n",
    "DATA_PATH = r\"C:\\Users\\luwil\\Documents\\misc_data\\modeldata.xlsx\"\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b11cb",
   "metadata": {},
   "source": [
    "## 3) Preprocessing Utilities - Data cleaning to drop unneeded columns, impute missing values, categorical one hot encoding, scaling numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8005c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DROP_COLS_DEFAULT = [\"Unnamed: 0\", \"member_id\", \"desc\"]   # obvious non-features\n",
    "POSSIBLE_DROP_IF_PRESENT = [\"emp_length\"]                 # keep emp_length_num instead if present\n",
    "\n",
    "def preprocess(df: pd.DataFrame, target_col: str = \"bad_flag\"):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop obvious columns if present\n",
    "    for c in DROP_COLS_DEFAULT + POSSIBLE_DROP_IF_PRESENT:\n",
    "        if c in df.columns:\n",
    "            df.drop(columns=[c], inplace=True)\n",
    "\n",
    "    # Identify test rows (bad_flag missing)\n",
    "    is_test = df[target_col].isna() if target_col in df.columns else pd.Series([False] * len(df))\n",
    "    train_df = df.loc[~is_test].copy()\n",
    "    test_df  = df.loc[is_test].copy()\n",
    "\n",
    "    # Target\n",
    "    y = None\n",
    "    if target_col in train_df.columns:\n",
    "        y = train_df[target_col].astype(int)\n",
    "        train_df.drop(columns=[target_col], inplace=True)\n",
    "    if target_col in test_df.columns:\n",
    "        test_df.drop(columns=[target_col], inplace=True)\n",
    "\n",
    "    # Separate types\n",
    "    cat_cols = train_df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    num_cols = train_df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "    # Keep ID for output but not as feature\n",
    "    id_col = None\n",
    "    for cand in [\"id\", \"ID\", \"Id\"]:\n",
    "        if cand in train_df.columns:\n",
    "            id_col = cand\n",
    "            if cand in num_cols: \n",
    "                num_cols.remove(cand)\n",
    "            break\n",
    "\n",
    "    # Impute missing\n",
    "    for c in cat_cols:\n",
    "        train_df[c] = train_df[c].fillna(\"Unknown\")\n",
    "    for c in num_cols:\n",
    "        med = train_df[c].median() # we use median here as it is robust to outliers.\n",
    "        train_df[c] = train_df[c].fillna(med)\n",
    "    # impute missing using the training portion of the dataset to prevent data leakage\n",
    "    if len(test_df) > 0:\n",
    "        for c in cat_cols:\n",
    "            if c in test_df.columns:\n",
    "                test_df[c] = test_df[c].fillna(\"Unknown\")\n",
    "        for c in num_cols:\n",
    "            if c in test_df.columns:\n",
    "                med = train_df[c].median()\n",
    "                test_df[c] = test_df[c].fillna(med)\n",
    "\n",
    "    # One-hot encode categoricals across combined frame to align columns\n",
    "    combined = pd.concat([train_df, test_df], axis=0, sort=False)\n",
    "    combined = pd.get_dummies(combined, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    # Split back\n",
    "    X_all   = combined\n",
    "    X_train = X_all.iloc[: len(train_df)].copy()\n",
    "    X_test  = X_all.iloc[len(train_df):].copy()\n",
    "\n",
    "    # Scale numeric columns only\n",
    "    scaler = StandardScaler()\n",
    "    if num_cols:\n",
    "        scaler.fit(X_train[num_cols].values)\n",
    "        X_train.loc[:, num_cols] = scaler.transform(X_train[num_cols].values)\n",
    "        if len(X_test) > 0:\n",
    "            X_test.loc[:, num_cols]  = scaler.transform(X_test[num_cols].values)\n",
    "\n",
    "    feature_cols = X_train.columns.tolist()\n",
    "    return X_train, y, X_test, feature_cols, scaler, id_col\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d84ec",
   "metadata": {},
   "source": [
    "## 4) Run Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780eac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (189457, 36) Test shape: (102505, 36) Features: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.83870292  1.56511359 -0.29013967 ...  0.2029509  -1.02977552\n",
      "  1.6822226 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, num_cols] = scaler.transform(X_train[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.55534196 -0.55534196 -0.55534196 ...  1.80069231 -0.55534196\n",
      "  1.80069231]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, num_cols] = scaler.transform(X_train[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.77792947 -0.77792947  0.19018745 ... -0.77792947  0.19018745\n",
      "  1.15830436]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, num_cols] = scaler.transform(X_train[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.84053772  1.56832764 -0.29048185 ...  0.20267169 -1.03021216\n",
      "  1.6821323 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, num_cols] = scaler.transform(X_train[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.61905799  0.09496643  0.70376619 ...  1.44785479 -0.61905799\n",
      "  1.04198828]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, num_cols] = scaler.transform(X_train[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.87359119  1.14470019  1.14470019 ...  1.14470019 -0.87359119\n",
      "  1.14470019]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, num_cols] = scaler.transform(X_train[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.53668495 -1.59682967 -0.90650287 ... -1.52286608  0.78233232\n",
      " -0.53668495]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, num_cols]  = scaler.transform(X_test[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.55534196 -0.55534196 -0.55534196 ... -0.55534196  1.80069231\n",
      " -0.55534196]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, num_cols]  = scaler.transform(X_test[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.19018745 -0.77792947 -0.77792947 ...  0.19018745  1.15830436\n",
      " -0.77792947]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, num_cols]  = scaler.transform(X_test[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.53705862 -1.59923547 -0.90692377 ... -1.5233657   0.78117872\n",
      " -0.53705862]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, num_cols]  = scaler.transform(X_test[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.61905799 -0.61905799 -0.61905799 ... -0.61905799  1.17727712\n",
      "  0.14757875]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, num_cols]  = scaler.transform(X_test[num_cols].values)\n",
      "C:\\Users\\luwil\\AppData\\Local\\Temp\\ipykernel_19588\\717782101.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.87359119 -0.87359119 -0.87359119 ... -0.87359119  1.14470019\n",
      "  1.14470019]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, num_cols]  = scaler.transform(X_test[num_cols].values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bad_flag\n",
       "0    0.930707\n",
       "1    0.069293\n",
       "Name: class_ratio, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_df, y, X_test_df, feature_cols, scaler, id_col = preprocess(df, target_col=\"bad_flag\")\n",
    "print(\"Train shape:\", X_train_df.shape, \"Test shape:\", X_test_df.shape, \"Features:\", len(feature_cols))\n",
    "y.value_counts(normalize=True).rename(\"class_ratio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33676d89-2b35-4d3f-ace3-c4561ce3eee0",
   "metadata": {},
   "source": [
    "### define MLP class and dataset type class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad07adf7-818f-436c-90ce-cde1927b70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabular dataset is a function to make our dataset able to be used with pytorch's dataloader function\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray | None = None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: List[int], dropout: float = 0.2, use_bn: bool = True):\n",
    "        super().__init__()\n",
    "        layers: List[nn.Module] = []\n",
    "        prev = in_dim\n",
    "        for h in hidden:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            if use_bn:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))  # binary logit\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)  # logits\n",
    "\n",
    "#%% md\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in loader:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(Xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in loader:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        logits = model(Xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "        all_logits.append(logits.detach().cpu().numpy())\n",
    "        all_targets.append(yb.detach().cpu().numpy())\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    logits = np.concatenate(all_logits)\n",
    "    targets = np.concatenate(all_targets).astype(int)\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(targets, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    pr, rc, f1, _ = precision_recall_fscore_support(targets, preds, average=\"binary\", zero_division=0)\n",
    "    return {\"loss\": avg_loss, \"auc\": auc, \"acc\": acc, \"precision\": pr, \"recall\": rc, \"f1\": f1}\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience: int = 5, mode: str = \"max\"):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.best = -float(\"inf\") if mode == \"max\" else float(\"inf\")\n",
    "        self.count = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, metric_value, model):\n",
    "        improved = (metric_value > self.best) if self.mode == \"max\" else (metric_value < self.best)\n",
    "        if improved:\n",
    "            self.best = metric_value\n",
    "            self.count = 0\n",
    "            self.best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            return True\n",
    "        else:\n",
    "            self.count += 1\n",
    "            return False\n",
    "\n",
    "    def should_stop(self):\n",
    "        return self.count >= self.patience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e012d1c9-fc17-427f-9be9-4155c7336ec6",
   "metadata": {},
   "source": [
    "### create train/validation split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd14ce9-56e9-423e-bf9b-eb153241847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_df.astype(np.float32).values, \n",
    "    y.astype(np.float32).values,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y.values\n",
    ")\n",
    "\n",
    "train_ds = TabularDataset(X_train, y_train)\n",
    "val_ds   = TabularDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=512, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=512, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4c82a-2615-4239-935c-d40a670c0d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d385e-ba01-47f4-8972-325ab3759ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
